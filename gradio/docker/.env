# This file contains the environment variables that are used by the docker-compose.yml file

# The UID and GID of the user that will be created in the container
# This is used to ensure that the files created by the container are owned by the host user
MY_UID=1000
MY_GID=1000

# The path to the selected models
LAYPA_MODEL_PATH=/mnt/c/PERSONAL/SMART-X/TESIS/SourceCode/loghi/models/laypa_general/baseline
LOGHI_MODEL_PATH=/mnt/c/PERSONAL/SMART-X/TESIS/SourceCode/loghi/models/generic-2023-02-15

# The path to the Loghi Tooling configuration file
# An example configuration file can be found in the Loghi repository at
# loghi/webservice/loghi-tooling/configuration.yml
TOOLING_CONFIG_FILE=/mnt/c/PERSONAL/SMART-X/TESIS/SourceCode/loghi/webservice/loghi-tooling/configuration.yml
# The path to the output directories
# NOTE: The directories must exist before running the container to avoid permission errors
LAYPA_OUTPUT_PATH=/mnt/c/PERSONAL/SMART-X/TESIS/SourceCode/loghi/laypa
LOGHI_OUTPUT_PATH=/mnt/c/PERSONAL/SMART-X/TESIS/SourceCode/loghi/loghi-htr
TOOLING_OUTPUT_PATH=/mnt/c/PERSONAL/SMART-X/TESIS/SourceCode/loghi/loghi-tooling

# The number of GPUs that are available to each container
# NOTE: If you have a single GPU, it is recommended to set the LAYPA_GPU_COUNT to 0
#       and the HTR_GPU_COUNT to 1. It is possible to run both models on a single GPU
#       but this can lead to out of memory errors for large images and big workloads.
LAYPA_GPU_COUNT=0
HTR_GPU_COUNT=1

# The load balancer settings for the Gradio server
# A higher queue size will allow more requests to be queued before they are processed
# A higher number of workers will allow more requests to be processed simultaneously
GRADIO_QUEUE_SIZE=10
GRADIO_WORKERS=1
